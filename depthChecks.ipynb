{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit each transit with a GP + transit. Lock all parameters except rprs and ars.\n",
    "\n",
    "This code is only minimally modified from https://github.com/AnaLopezMurillo/TaurusTTVs\n",
    "\n",
    "If you find this code helpful in your research, please cite Barber et al. in prep and Lopez Murillo et al. in prep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightkurve as lk\n",
    "from lightkurve import LightCurveCollection\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import batman\n",
    "from scipy.optimize import curve_fit\n",
    "import emcee\n",
    "from scipy.optimize import minimize\n",
    "import re\n",
    "from scipy import stats\n",
    "import corner\n",
    "import matplotlib.gridspec as gridspec\n",
    "import celerite2\n",
    "from celerite2 import terms\n",
    "import scipy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA UPLOAD\n",
    "lc_path = './LCs/extractedLC.txt'\n",
    "\n",
    "df = pd.read_csv(lc_path, delimiter=\" \")\n",
    "time_array = df[\"time\"].to_numpy()\n",
    "data = df[\"flux\"].to_numpy()\n",
    "ferr = df[\"flerr\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filenames:\n",
    "chainfile = './LCs/emceechain-56658270.npy'\n",
    "probfile = './LCs/emceeprob-56658270.npy'\n",
    "\n",
    "## read in the npy file\n",
    "chain = np.load(chainfile) ## contains the parameters at each step\n",
    "prob = np.load(probfile)   ## contains the probabilities (likelihoods) at each step\n",
    "\n",
    "## flatten the chain/probs + remove burn in\n",
    "ndim = (np.shape(chain))[2]\n",
    "nburnin= chain.shape[1]//3\n",
    "samples=chain[:,nburnin:,:].reshape((-1,ndim))\n",
    "probs=prob[:,nburnin:].reshape((-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time_array, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Median Function - used for plotting\n",
    "def runmed(a,b,size): # a= time array, b= flux array, size=size of bin\n",
    "    meda = []\n",
    "    medb = []\n",
    "    for i in np.arange(np.min(a),np.max(a),size):\n",
    "        l = np.where((a > i) & (a<(i+size)))\n",
    "        meda.append(np.median(a[l]))\n",
    "        medb.append(np.median(b[l]))\n",
    "    return meda,medb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get highest likelihood set of parameters:\n",
    "l = np.squeeze((np.where(probs == np.max(probs))))[1] ## many points may have equal likelihood, it doesn't matter which you select\n",
    "best = samples[l,:]\n",
    "\n",
    "logP = best[7]\n",
    "logamp = best[8]\n",
    "logQ1 = best[9]\n",
    "logQ2 = best[10]\n",
    "logmix = best[11]\n",
    "\n",
    "t0 = best[0]\n",
    "per = best[1]\n",
    "rp = best[2]\n",
    "b = best[3]\n",
    "rho = best[4]\n",
    "q1 = best[5]\n",
    "q2 = best[6]\n",
    "w = 0.\n",
    "ecc = 0.0\n",
    "\n",
    "ars = 215.*rho**(1./3.)*(per/365.25)**(2./3.)\n",
    "inc = np.arccos(b/ars)*180./np.pi  \n",
    "\n",
    "window = 1.0\n",
    "t0_guess = t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDepthPosterior = samples[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transit model\n",
    "def transit(t, rp, a):\n",
    "    params = batman.TransitParams()\n",
    "    params.t0 = t0_guess                 \n",
    "    params.per = per             \n",
    "    params.rp = rp                 \n",
    "    params.a = a                \n",
    "    params.inc = inc                \n",
    "    params.ecc = ecc                  \n",
    "    params.w = w                   \n",
    "    params.u = [0.29, 0.329]          \n",
    "    params.limb_dark = \"quadratic\"  \n",
    "\n",
    "    m = batman.TransitModel(params, t)\n",
    "    flux = m.light_curve(params)      \n",
    "    return flux \n",
    "\n",
    "# MCMC functions\n",
    "def set_params(theta, time, gp, err):\n",
    "    rp, a, logsigma, logrho, logQ = theta\n",
    "    gp.kernel = terms.SHOTerm(sigma=np.exp(logsigma), rho=np.exp(logrho), Q=np.exp(logQ)) \n",
    "    gp.compute(time, yerr=err, quiet=True)\n",
    "    return gp\n",
    "\n",
    "def ln_likelihood(theta, time, gp, data, err):\n",
    "    rp, a, logsigma, logrho, logQ = theta\n",
    "    try: \n",
    "        gp = set_params(theta, time, gp, err)\n",
    "    except ZeroDivisionError:\n",
    "        return -np.inf\n",
    "    model = transit(time, rp, a)\n",
    "    return gp.log_likelihood(data-model)\n",
    "\n",
    "\n",
    "def ln_prior(theta):\n",
    "    rp, a, logsigma, logrho, logQ = theta\n",
    "    sigma = np.exp(logsigma)\n",
    "    rho = np.exp(logrho)\n",
    "    Q = np.exp(logQ)\n",
    "    \n",
    "    if rp < .0676 - (0.0024*10) or rp > .0676 + (0.0024*10) or a > 20 or a < 0 or (Q == 0) or (rho == 0) or (sigma == 0):\n",
    "        return -np.inf\n",
    "   \n",
    "    sigma_sigma2 = 20.0\n",
    "    lp1 = -0.5*np.sum((sigma)**2/sigma_sigma2 + np.log(2*np.pi*sigma_sigma2))\n",
    "    sigma_q2 = 20.0\n",
    "    lp3 = -0.5*np.sum((Q)**2/sigma_q2 + np.log(2*np.pi*sigma_q2))\n",
    "    return lp1+lp3\n",
    "\n",
    "def ln_probability(theta, time, gp, data, err):\n",
    "    lp = ln_prior(theta)\n",
    "    if not np.isfinite(lp):\n",
    "        return -np.inf\n",
    "    lnlike = ln_likelihood(theta, time,gp,data,err)\n",
    "    if not np.isfinite(lnlike):\n",
    "        return -np.inf\n",
    "    return lp + lnlike\n",
    "\n",
    "def initWalkers(theta_0, ndim, nwalkers):\n",
    "    \n",
    "    perturbation = [0.001, 0.001, 0.001, 0.001, 0.001]\n",
    "    rng = np.random.default_rng()\n",
    "    \n",
    "    pos = []\n",
    "    \n",
    "    while len(pos) < nwalkers:\n",
    "        p = theta_0 + perturbation*rng.standard_normal(ndim)\n",
    "        \n",
    "        if np.isfinite(ln_prior(p)):\n",
    "            pos.append(p)\n",
    "    \n",
    "    return pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle the TESS data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tt = []\n",
    "chi2 = []\n",
    "\n",
    "depths = []\n",
    "ars = []\n",
    "depthUncerts = []\n",
    "axesUncerts = []\n",
    "depthChains = []\n",
    "arsChains = []\n",
    "\n",
    "transit_num = -1\n",
    "\n",
    "rho_0 = 10**logP\n",
    "logQ_0 = .7\n",
    "t0_guess = t0\n",
    "\n",
    "for i in np.arange(-1000,3000, 1):\n",
    "    t0_guess = t0+(per*i)\n",
    "    rho = 1.4\n",
    "    logQ = .7\n",
    "\n",
    "    initial = [0.0673, 11.81, -4,  np.log(rho_0),  logQ_0]\n",
    "\n",
    "    window = 0.7\n",
    "\n",
    "    ll = np.where((time_array > t0_guess - window) & (time_array < t0_guess + window))\n",
    "    ll2 = np.where((time_array > t0_guess - 0.1) & (time_array < t0_guess + 0.1))\n",
    "\n",
    "    if (np.size(ll) > 10) and (np.size(ll2) > 0):\n",
    "        print(t0_guess)\n",
    "        y = np.array(data[ll])\n",
    "        t = np.array(time_array[ll])\n",
    "        err = np.array(ferr[ll])\n",
    "\n",
    "        transit_num+=1\n",
    "\n",
    "        term2 = terms.SHOTerm(sigma=np.exp(initial[2]), rho=np.exp(initial[3]), Q=np.exp(initial[4]))\n",
    "        kernel = term2        \n",
    "        \n",
    "        gp = celerite2.GaussianProcess(kernel, mean=0.0)\n",
    "        gp.compute(t, yerr=err)\n",
    "        print(\"Initial log likelihood: {0}\".format(gp.log_likelihood(y)))\n",
    "\n",
    "        ln_probability(initial,t,gp,y,err)\n",
    "\n",
    "        # set up MCMC sampler\n",
    "        max_n = 1000\n",
    "        nwalkers = 10\n",
    "        initial_positions = initWalkers(initial, len(initial), nwalkers)\n",
    "\n",
    "        sampler = emcee.EnsembleSampler(nwalkers, len(initial), ln_probability, args=(time_array[ll], gp, data[ll], err), threads=8)\n",
    "\n",
    "        index = 0\n",
    "        autocorr = np.empty(max_n)\n",
    "        autcorrreq = 50\n",
    "        autcorr_change_frac = 0.1\n",
    "        old_tau = np.inf\n",
    "\n",
    "        for sample in sampler.sample(initial_positions, iterations=max_n, progress=True):\n",
    "            # Check convergence every 1000 steps\n",
    "            if sampler.iteration % 1000:\n",
    "                continue\n",
    "            \n",
    "            # Compute the autocorrelation time so far\n",
    "            # Using tol=0 means that we'll always get an estimate even if it isn't trustworthy\n",
    "            tau = sampler.get_autocorr_time(tol=0)\n",
    "            autocorr[index] = np.mean(tau)\n",
    "            index += 1\n",
    "\n",
    "            # Check convergence\n",
    "            converged = np.all(tau * autcorrreq < sampler.iteration)\n",
    "            converged &= np.all(np.abs((old_tau - tau) / tau) < autcorr_change_frac)\n",
    "            if converged:\n",
    "                break\n",
    "            old_tau = tau\n",
    "\n",
    "        ## burn and flat samples finding\n",
    "        burn = sampler.iteration//5\n",
    "        flat_samples = sampler.get_chain(discard=burn, thin=3, flat=True)\n",
    "        mcmc = np.percentile(flat_samples[:, 0], [16, 50, 84])\n",
    "\n",
    "        samples = sampler.get_chain(discard=burn)\n",
    "        flats = np.concatenate(samples)\n",
    "\n",
    "        # walker plot\n",
    "        ndim = len(initial)\n",
    "        labels = [r'$rp/rs$', r'$a/rs$', r'$\\ln{\\sigma}$',r'$\\ln{\\rho}$',r'$\\ln{Q}$']\n",
    "        fig, axes = plt.subplots(ndim, figsize=(10, 7), sharex=True, facecolor=\"white\")\n",
    "        for i in range(ndim):\n",
    "            ax = axes[i] \n",
    "            ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
    "            ax.set_xlim(0, len(samples))\n",
    "            ax.set_ylabel(labels[i])\n",
    "            ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "        plt.show()\n",
    "\n",
    "        # corner plot\n",
    "        flat_samples = sampler.get_chain(discard=burn, flat=True)\n",
    "        fig = corner.corner( \n",
    "            flat_samples,show_titles=True,labels=labels,quantiles=(0.16, 0.84),\n",
    "            fill_contours=True, plot_datapoints=False,title_kwargs={\"fontsize\": 9},title_fmt='.3f',\n",
    "            hist_kwargs={\"linewidth\": 2.5},levels=[(1-np.exp(-0.5)),(1-np.exp(-2)),(1-np.exp(-4.5))],\n",
    "            title_quantiles=[0.16, 0.5, 0.84]\n",
    "        )\n",
    "        plt.show()\n",
    "\n",
    "        # data model plot\n",
    "        fig, axes = plt.subplots(1, figsize=(10, 7), sharex=True)\n",
    "        result = np.median(flat_samples,axis=0)\n",
    "        set_params(result, t, gp, err)\n",
    "        model = transit(t,result[0], result[1])\n",
    "        mu, variance = gp.predict(y-model, t, return_var=True)\n",
    "        sigma = np.sqrt(variance)\n",
    "        axes.plot(t,model,color='r')\n",
    "\n",
    "        marker = \".\"\n",
    "        if (np.size(ll) < 2500):\n",
    "            marker=\"o\"\n",
    "        axes.scatter(t,y-mu, marker=marker, alpha=0.2, color='r')\n",
    "        if np.size(ll) > 100:\n",
    "            bint, binfl = runmed(t, y - mu, 0.33/24.)\n",
    "            plt.scatter(bint, binfl, marker='o', alpha=0.5, color='b')\n",
    "        plt.title('Transit #' + str(transit_num))\n",
    "        plt.show()\n",
    "\n",
    "        print(\" \")\n",
    "        print(\" \")\n",
    "\n",
    "        tt.append(t0_guess)\n",
    "\n",
    "        depths.append(result[0])\n",
    "        ars.append(result[1])\n",
    "        depthUncerts.append(np.std(flats[:,0]))\n",
    "        axesUncerts.append(np.std(flats[:,1]))\n",
    "        \n",
    "        depthChains.append(flat_samples[:,0])\n",
    "        arsChains.append(flat_samples[:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
